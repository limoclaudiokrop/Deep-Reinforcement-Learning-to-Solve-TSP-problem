{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fe3125",
   "metadata": {},
   "source": [
    "# Traveling Salesman Problem (TSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce734ab",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "486897c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 98.0, 84.0, 74.0, 65.0, 50.0, 43.0, 37.0, 28.0, 19.0, 8.0, 96.0, 82.0, 77.0, 62.0, 59.0, 48.0, 30.0, 22.0, 12.0, 3.0, 93.0, 88.0, 71.0, 69.0, 53.0, 49.0, 35.0, 27.0, 18.0, 3.0, 95.0, 88.0, 72.0, 63.0, 55.0, 42.0, 36.0, 28.0, 17.0, 5.0, 90.0, 85.0, 75.0, 66.0, 55.0, 44.0, 33.0, 22.0]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def readData():\n",
    "    states = []\n",
    "    long_lats = []\n",
    "    prizes = []\n",
    "    with open(\"file.txt\") as file:\n",
    "        for line in file:\n",
    "            words = line.split(',')\n",
    "            longs = words[1].split()\n",
    "            \n",
    "            arr = []\n",
    "            states.append(words[0] + \",\" + longs[0])\n",
    "            arr.append(float(longs[1]))\n",
    "            arr.append(float(longs[2]))\n",
    "            prizes.append(float(longs[3]))\n",
    "            long_lats.append(arr)\n",
    "            \n",
    "    return states, long_lats, prizes\n",
    "\n",
    "states, long_lats, prizes = readData()\n",
    "\n",
    "\n",
    "def calcDistance(c1, c2):\n",
    "    return ((c1[0] - c2[0])**2 + (c1[1]-c2[1])**2)**0.5\n",
    "\n",
    "def getDistanceBtwCities(c1, c2):\n",
    "    return calcDistance(long_lats[c1], long_lats[c2])\n",
    "\n",
    "    \n",
    "def distMatrix(data):\n",
    "    matrix = []\n",
    "    for i,d in enumerate(data):\n",
    "        arr = []\n",
    "        for j,d1 in enumerate(data):\n",
    "            if i == j:\n",
    "                arr.append(0)\n",
    "            else:\n",
    "                arr.append(calcDistance(data[i], data[j]))\n",
    "        matrix.append(arr)\n",
    "    return matrix\n",
    "\n",
    "dist_matrix = distMatrix(long_lats)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a64428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33394ab5",
   "metadata": {},
   "source": [
    "# 1. Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e4cb249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prize Collected:  193.0\n",
      "Sequence:  [10, 13, 22, 31, 15]\n",
      "Distance:  8.961726382430495\n",
      "Time of execution:  0.0010681000003387453\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "def Greedy(start, end, prize_collect):\n",
    "    tot = 0\n",
    "    tot = tot - prizes[start] - prizes[end]\n",
    "    visited = []\n",
    "    currCity = start\n",
    "    sequence = []\n",
    "    sequence.append(start)\n",
    "    dist = 0\n",
    "    while tot < prize_collect:\n",
    "        max_ratio = 0\n",
    "        index = 0\n",
    "        for i,d in enumerate(long_lats):\n",
    "            if i in visited or i == end or i == start or i == currCity:\n",
    "                continue\n",
    "            ratio = prizes[i]/(dist_matrix[i][currCity])\n",
    "            if ratio > max_ratio:\n",
    "                max_ratio = ratio\n",
    "                index = i\n",
    "        dist = dist + dist_matrix[currCity][index]\n",
    "        currCity = index\n",
    "        visited.append(currCity)\n",
    "        tot = tot + prizes[index]\n",
    "        sequence.append(currCity)\n",
    "    \n",
    "    sequence.append(end)\n",
    "    \n",
    "    et = time.time()\n",
    "    print(\"Total Prize Collected: \", tot)\n",
    "    print(\"Sequence: \", sequence)\n",
    "    print(\"Distance: \", dist)\n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "Greedy(10, 15, 100)\n",
    "stop = timeit.default_timer()\n",
    "print('Time of execution: ', stop - start) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec2ecf",
   "metadata": {},
   "source": [
    "# Random Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11c327fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prize Collected:  172.0\n",
      "Sequence:  [10, 2, 14, 21, 15]\n",
      "Distance:  61.93801216504909\n",
      "Time of execution:  0.0005274000000099477\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import timeit\n",
    "def RandomAlgorithm(start, end, prize_collect):\n",
    "    tot = 0\n",
    "    tot = tot - prizes[start] - prizes[end]\n",
    "    visited = []\n",
    "    currCity = start\n",
    "    sequence = []\n",
    "    sequence.append(start)\n",
    "    n = len(prizes)\n",
    "    dist = 0\n",
    "    while tot < prize_collect:\n",
    "        index = random.randint(0,n-1)\n",
    "        if index not in visited:\n",
    "            dist = dist + dist_matrix[currCity][index]\n",
    "            currCity = index\n",
    "            visited.append(currCity)\n",
    "            tot = tot + prizes[index]\n",
    "            sequence.append(currCity)\n",
    "    \n",
    "    sequence.append(end)\n",
    "    print(\"Total Prize Collected: \", tot)\n",
    "    print(\"Sequence: \", sequence)\n",
    "    print(\"Distance: \", dist)\n",
    "    \n",
    "start = timeit.default_timer()\n",
    "    \n",
    "RandomAlgorithm(10,15,100)\n",
    "stop = timeit.default_timer()\n",
    "print('Time of execution: ', stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db514381",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "825a0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prize Collected:  194.0\n",
      "Sequence:  [10, 13, 18, 31, 15]\n",
      "Distance:  26.04699583364093\n",
      "Time of execution:  0.0070238999996945495\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def RL(start, end, prize_collect):\n",
    "    \n",
    "    #Initialize variables\n",
    "    num_agents = 10\n",
    "    visited = []\n",
    "    paths = []\n",
    "    lengths = []\n",
    "    curr_nodes = []\n",
    "    tot_prizes = []\n",
    "    best_agent = 0\n",
    "    for n in range(num_agents):\n",
    "        visited.append([])\n",
    "        paths.append([start])\n",
    "        lengths.append(0)\n",
    "        curr_nodes.append(start)\n",
    "        tot_prizes.append(0)\n",
    "        \n",
    "    n = len(prizes)\n",
    "    \n",
    "    #Initialize Q table and reward table\n",
    "    Q_table = []\n",
    "    Reward_table = []\n",
    "    sum_dist = 0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            sum_dist = sum_dist + dist_matrix[i][j]\n",
    "    for i in range(n):\n",
    "        arr = []\n",
    "        arr2 = []\n",
    "        for j in range(n):\n",
    "            val = (n*n)/(n*sum_dist)\n",
    "            arr.append(val)\n",
    "            arr2.append(0)\n",
    "        Q_table.append(arr)\n",
    "        Reward_table.append(arr2)\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    discount = 0.3\n",
    "    alpha = 1.1\n",
    "    beta = 1.1\n",
    "    w = 10\n",
    "    prob_q = 5\n",
    "    \n",
    "    #Run algorithm for 100 iterations\n",
    "    for it in range(100):\n",
    "        for i in range(n):\n",
    "            #Select next action for all the agents\n",
    "            for m in range(num_agents):\n",
    "                if tot_prizes[m] > prize_collect:\n",
    "                    continue\n",
    "                    \n",
    "                currCity = curr_nodes[m]\n",
    "                q = random.randint(0,10)\n",
    "                index = 0\n",
    "                #Either explore or exploit with probability 0.5\n",
    "                if q < prob_q:\n",
    "                    index = 0\n",
    "                    max_t = 0\n",
    "                    #Select best state next\n",
    "                    for c in range(n):\n",
    "                        if c not in visited[m] and c != currCity and c != start and c != end:\n",
    "                            ratio = pow(Q_table[c][currCity],alpha)/pow(dist_matrix[c][currCity],beta)\n",
    "                            if ratio > max_t:\n",
    "                                max_t = ratio\n",
    "                                index = c\n",
    "                else:\n",
    "                    sum_probs = 0\n",
    "                    probs = []\n",
    "                    probs_indices =[]\n",
    "                    #Select next state according to uniformly distributed weighted probabilities\n",
    "                    for c in range(n):\n",
    "                        if c not in visited[m] and c != currCity and c != start and c != end:\n",
    "                            ratio = pow(Q_table[c][currCity],alpha)/pow(dist_matrix[c][currCity],beta)\n",
    "                            probs.append(ratio)\n",
    "                            probs_indices.append(c)\n",
    "                            sum_probs = sum_probs + ratio\n",
    "                    for i,p in enumerate(probs):\n",
    "                        probs[i] = p/sum_probs\n",
    "                        \n",
    "                    index = random.choices(population=probs_indices, weights=probs,k=1)[0]\n",
    "                \n",
    "                \n",
    "                visited[m].append(currCity)   \n",
    "                paths[m].append(index)\n",
    "                curr_nodes[m] = index\n",
    "                tot_prizes[m] = tot_prizes[m] + prizes[index]\n",
    "                lengths[m] = lengths[m] + dist_matrix[index][currCity]\n",
    "                #Update Q table\n",
    "                val = (1-learning_rate)*Q_table[index][currCity]\n",
    "                max_t = 0\n",
    "                for c in range(n):\n",
    "                    if c not in visited[m] and c != index and c != start and c != end:\n",
    "                            if Q_table[c][index] > max_t:\n",
    "                                max_t = Q_table[c][index]\n",
    "                val = val + learning_rate*discount*max_t\n",
    "                Q_table[currCity][index] = val\n",
    "                \n",
    "        #Find best agent\n",
    "        max_t = 0\n",
    "        index = 0\n",
    "        for m in range(num_agents):\n",
    "            ratio = tot_prizes[m]/lengths[m]\n",
    "            if ratio > max_t:\n",
    "                max_t = ratio\n",
    "                index = m\n",
    "        prev = start\n",
    "        best_agent = index\n",
    "        for p in paths[index]:\n",
    "            #Update reward table\n",
    "            Reward_table[start][p] = tot_prizes[index]/lengths[index]\n",
    "            val = Q_table[start][p]*(1-learning_rate)\n",
    "            max_t = 0\n",
    "            for i in range(n):\n",
    "                if i != p:\n",
    "                    if Q_table[p][i] > max_t:\n",
    "                        max_t = Q_table[p][i]\n",
    "            val = val + learning_rate*(Reward_table[start][p] + max_t)\n",
    "            Q_table[start][p] = val\n",
    "            start = p\n",
    "        for n in range(num_agents):\n",
    "            visited.append([])\n",
    "            paths.append([start])\n",
    "            lengths.append(0)\n",
    "            curr_nodes.append(start)\n",
    "            tot_prizes.append(0)\n",
    "    \n",
    "    paths[best_agent].append(end)\n",
    "    lengths[best_agent] = lengths[best_agent] + dist_matrix[curr_nodes[best_agent]][end]\n",
    "    print(\"Total Prize Collected: \", tot_prizes[best_agent])\n",
    "    print(\"Sequence: \", paths[best_agent])\n",
    "    print(\"Distance: \", lengths[best_agent])\n",
    "    \n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "RL(10,15,100)         \n",
    "stop = timeit.default_timer()\n",
    "print('Time of execution: ', stop - start)               \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269afc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
